<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>查分隐私 | Academic</title>
    <link>https://Zhang-maozhen.github.io/category/%E6%9F%A5%E5%88%86%E9%9A%90%E7%A7%81/</link>
      <atom:link href="https://Zhang-maozhen.github.io/category/%E6%9F%A5%E5%88%86%E9%9A%90%E7%A7%81/index.xml" rel="self" type="application/rss+xml" />
    <description>查分隐私</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language>
    <image>
      <url>https://Zhang-maozhen.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>查分隐私</title>
      <link>https://Zhang-maozhen.github.io/category/%E6%9F%A5%E5%88%86%E9%9A%90%E7%A7%81/</link>
    </image>
    
    <item>
      <title>差分隐私</title>
      <link>https://Zhang-maozhen.github.io/post/%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/differential-privacy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://Zhang-maozhen.github.io/post/%E5%B7%AE%E5%88%86%E9%9A%90%E7%A7%81/differential-privacy/</guid>
      <description>&lt;h1 id=&#34;差分隐私&#34;&gt;差分隐私&lt;/h1&gt;
&lt;h2 id=&#34;差分隐私概念&#34;&gt;差分隐私概念&lt;/h2&gt;
&lt;p&gt;差分隐私是算法的属性，而不是数据的属性，我们证明一个算法满足差分隐私。&lt;/p&gt;
&lt;p&gt;证明数据集满足差分隐私则必须证明产生它的算法满足差分隐私。&lt;/p&gt;
&lt;p&gt;&lt;font color=&#34;#FF0000&#34;&gt;满足查分隐私的功能通常称为机制。如果对于所有相邻数据集$x,x&amp;rsquo;$，以及所有可能的输出$S$，则机制$F$满足差分隐私&lt;/font&gt;
$$
\frac{Pr[F(x)=S]}{PR[F(x&amp;rsquo;)=S]}{≤e^ε}
$$&lt;/p&gt;
&lt;p&gt;$F$是一个随机函数，所以并不是一个点的分布，而是一个描述输出结果的概率分布&lt;/p&gt;
&lt;p&gt;$F$内置的随即向宁应该是足够的，从$F$得到的输出不会揭示$x或x&amp;rsquo;$中的哪一个是输入；如果判断不出哪一个是输入，那么就无法判断数据是否存在于输入中&lt;/p&gt;
&lt;p&gt;$ϵ$是隐私预算，较小的$\epsilon$要求$F$在给定相似输入时得到相似的输出，这样提供了更高级别的隐私，较大的${\epsilon}$允许的输出相似性较低，提供的隐私性较低&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ϵ$是隐私预算小，隐私性比较高&lt;/li&gt;
&lt;li&gt;$ϵ$是隐私预算大，隐私性比较低（隐私越少，是差分隐私差分出来的信息越少？  ）&lt;/li&gt;
&lt;li&gt;一般而言，${\epsilon}$在1左右或更小，当${\epsilon}$大于10时对隐私保护没有多少作用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;${\epsilon}$是差分隐私&lt;/p&gt;
&lt;h3 id=&#34;拉普拉斯机制&#34;&gt;拉普拉斯机制&lt;/h3&gt;
&lt;p&gt;差分隐私领域已经开发了一些基本机制，准确描述了使用什么样的噪声以及使用多少噪声，其中之一被称为拉普拉斯机制&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;拉普拉斯机制，对于返回数字的函数$f(x)$，$F(x)$的以下定义满足${\epsilon}$-差分隐私：
$$
F(x) = f(x) + Lap(\frac{s}{\epsilon})
$$
$s$是$f$的敏感度，$Lap(s)$表示从中心为0且尺度为$s$的拉普拉斯分布中采样。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;函数f的敏感度是当输入变化1时f的输出变化量。【计数查询的灵敏度始终为1】&lt;/p&gt;
&lt;p&gt;使用灵敏度为1和我们选择的$\epsilon$的拉普拉斯机制来实现差分隐私，选择$\epsilon=0.1$,使用&lt;code&gt;Numpy的random.laplace从拉普拉斯分布中采样&lt;/code&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;sensitivity&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;epsilon&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;adult&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;adult&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Age&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;40&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;laplace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scale&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sensitivity&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;epsilon&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;差分隐私的属性&#34;&gt;差分隐私的属性&lt;/h2&gt;
&lt;p&gt;它具有三个重要属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;顺序合成（Sequential composition）&lt;sup id=&#34;fnref1:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;并行合成（Parallel composition）&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;后处理（Post processing）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;顺序合成&#34;&gt;顺序合成&lt;/h3&gt;
&lt;p&gt;$F_1(x)$满足$\epsilon_1$-差分隐私，$F_2(x)$满足$\epsilon_2$-差分隐私，那么这两个机制的结果$G(x)=(F_1(x),F_2(x))$满足$\epsilon_1+\epsilon_2$-差分隐私&lt;/p&gt;
&lt;p&gt;顺序组合作为差分隐私的重要属性是因为它允许设计不止一次查询数据的算法。它可以使个人通过这些分析来约束产生的总隐私成本&lt;/p&gt;
&lt;p&gt;顺序组合给出的隐私成本界限是一个上限，两个特定的不同的私有版本的实际隐私成本可能小于这个值，但不能大于这个值&lt;/p&gt;
&lt;p&gt;顺序组合会产生多个版本的总${\epsilon}$上限，对隐私的实际积累影响可能更低，实际的因私损失似乎略低于顺序组合确定的上限${\epsilon}$。&lt;/p&gt;
&lt;h3 id=&#34;并行合成&#34;&gt;并行合成&lt;/h3&gt;
&lt;p&gt;并行组合基于将数据集拆分为不相交的块，并分别在每个块上运行差分私有机制。块是不想交的，因此每个人的数据恰好出现在一个块中，即便总共有k个块（因此运行k次，一个块一次）该机制叶芝在每个人的数据上运行一次。&lt;/p&gt;
&lt;h3 id=&#34;直方图统计&#34;&gt;直方图统计&lt;/h3&gt;
&lt;p&gt;直方图对于差分隐私而言，自动满足并行组合。直方图中的每个&amp;rsquo;bin&amp;rsquo;都通过数据属性的可能值定义，即Education = HS-gard。单行不会同时有一个属性的两个值，因此这种方式定义bin可以保证它们是不想交的。因此满足了并行组合的要求，并且可以使用差分隐私机制释放所有bin计数，总隐私成本为${\epsilon}$&lt;/p&gt;
&lt;h3 id=&#34;交叉表&#34;&gt;交叉表&lt;/h3&gt;
&lt;p&gt;一次计算数据集中具有多个属性的特定值的行的频率。经常用于分析数据时显示两个变量之间的关系。&lt;/p&gt;
&lt;h2 id=&#34;局部敏感性&#34;&gt;局部敏感性&lt;/h2&gt;
&lt;h3 id=&#34;通过局部敏感性实现差分隐私&#34;&gt;通过局部敏感性实现差分隐私&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Q：可以像全局敏感性一样使用拉普拉斯机制么？$F$的以下定义是否满足ε-差分隐私?&lt;/p&gt;
&lt;p&gt;A：$LS(f,x)$取决于数据集，如果分析师知道查询在数据集上的本地敏感性，那么他可以推断出数据集的一些信息&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;简记&#34;&gt;简记&lt;/h1&gt;
&lt;p&gt;Dwork2006年提出&lt;sup id=&#34;fnref2:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;查分隐私&lt;/p&gt;
&lt;p&gt;串行组合&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h1 id=&#34;文献&#34;&gt;文献&lt;/h1&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In &lt;em&gt;Proceedings of the Third Conference on Theory of Cryptography&lt;/em&gt;, TCC&#39;06, 265–284. Berlin, Heidelberg, 2006. Springer-Verlag. URL: &lt;a href=&#34;https://doi.org/10.1007/11681878_14&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1007/11681878_14&lt;/a&gt;, &lt;a href=&#34;https://doi.org/10.1007/11681878_14&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1007/11681878_14&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref1:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref2:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: privacy via distributed noise generation. In Serge Vaudenay, editor, &lt;em&gt;Advances in Cryptology - EUROCRYPT 2006&lt;/em&gt;, 486–503. Berlin, Heidelberg, 2006. Springer Berlin Heidelberg.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Frank D. McSherry. Privacy integrated queries: an extensible platform for privacy-preserving data analysis. In &lt;em&gt;Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data&lt;/em&gt;, SIGMOD &amp;lsquo;09, 19–30. New York, NY, USA, 2009. Association for Computing Machinery. URL: &lt;a href=&#34;https://doi.org/10.1145/1559845.1559850&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1145/1559845.1559850&lt;/a&gt;, &lt;a href=&#34;https://doi.org/10.1145/1559845.1559850&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi:10.1145/1559845.1559850&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;McSherry, Frank. Privacy integrated queries[J]. Communications of the Acm, 2010, 53(9):89. .&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
