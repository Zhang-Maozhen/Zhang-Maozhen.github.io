<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>联邦学习 | Academic</title>
    <link>https://Zhang-maozhen.github.io/category/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/</link>
      <atom:link href="https://Zhang-maozhen.github.io/category/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <description>联邦学习</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 29 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://Zhang-maozhen.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>联邦学习</title>
      <link>https://Zhang-maozhen.github.io/category/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/</link>
    </image>
    
    <item>
      <title>联邦学习 概念</title>
      <link>https://Zhang-maozhen.github.io/post/federatedlearningconcept/</link>
      <pubDate>Fri, 29 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://Zhang-maozhen.github.io/post/federatedlearningconcept/</guid>
      <description>&lt;h1 id=&#34;联邦学习--概念&#34;&gt;联邦学习  概念&lt;/h1&gt;
&lt;p&gt;传统的联邦学习的目标函数可写为：
$$
f(w)=\sum_{k=1}^K\frac{n_k}{n}F_k(w)\
F_k(w)=\frac{1}{n_k}\sum_{i=1}^{n_k}l(h(x_i;w),y_i)
$$
$K$为总结点个数，$n_k$为第$k$个节点的样本数。&lt;/p&gt;
&lt;p&gt;联邦学习训练过程中，会将数据按照Non-IID划分到各client节点，然后在各client节点的数据划分train/test/val。对于传统联邦学习而言，每个client都会使用全局模型$w$进行测试。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在IID条件下，在分布式优化中常假定$f(w)=\mathbb E_{D_k}[F_k(w)]$，其中$D_k$为第$k$个节点的数据集，此时就退化为传统的分布式机器学习。然而在数据Non-IID条件下，$F_k$就不是一个对$f$的良好近似，这意味着想训练一个模型$w$满足所有节点的要求难度很大&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;font color=&#34;#ED526&#34;&gt;【醒悟】：这就是联邦学习个性化么呀！&lt;/font&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;联邦学习个性化不求构建全局通用的模型$w$，而是为每个节点分别创建一个个性化的模型$w_k$&lt;/p&gt;
&lt;p&gt;个性化常见方法有：元学习、多任务学习、迁移学习&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;主要划分有：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;横向联邦学习、纵向联邦学习、迁移联邦学习&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;最初是由谷歌的H.Brendan McMahan等人提出，并将其应用落地&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;横向联邦学习&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;适用于特征重合多，样本重合较少的数据集进行联合计算的场景。以样本维度（横向）对数据集进行切分，以特征相同而样本不完全相同的数据部分为对象进行训练。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;谷歌在 2016 年提出的安卓手机模型更新数据联合建模方案就是利 用单个用户使用安卓手机时，不断在本地更新模型参 数并上传到安卓云上，从而使特征维度相同的各数据 拥有方联合建模&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img src=&#34;https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/20220704225948.png&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;&lt;strong&gt;纵向联邦学习&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;适用于样本重合较多，而特征重合较少的数据集间联合计算的场景。以特征维度（纵向）对数据集进行切分，以样本相同而特征不完全相同的数据集部分为对象进行训练&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如同一地区的银行和电商，两个机构在特定地区的用户群里交集较大，因此可以对不同维度的用户特征进行聚合以增强模型能力。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img src=&#34;https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20220705095039461.png&#34; alt=&#34;image-20220705095039461&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;&lt;strong&gt;联邦迁移学习&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;适用于数据集间样本和特征重合均较少的场景。在这样的场景中，不再对数据进行切分，而是利用迁移学习来弥补数据或标签的不足。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如不同地区、不同行业机构之间进行联合建模为例，用户群体和特征维度的交集都较小，联邦迁移学习即用来针对性解决单边数据规模小，标签样本少的问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img src=&#34;https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20220705095641894.png&#34; alt=&#34;image-20220705095641894&#34; style=&#34;zoom:50%;&#34; /&gt;&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Mcmahan H B, Moore E, Ramage D, et al. Communication-Efficient Learning of Deep Networks from Decentralized Data [J]. international conference on artificial intelligence and statistics, 2016.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
